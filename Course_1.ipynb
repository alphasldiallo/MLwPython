{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Course_1.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "9SxiIczg1s1k",
        "pclZR6uFklf_",
        "8UQgU5I-lEll",
        "RHRXds9U9134",
        "K4qgOdz7Yyeb",
        "Vlf6_berQ1vq",
        "zI6s2Amob48j",
        "zZX9MQlORLfY",
        "AQ69XKdbZcA3"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.7"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sigvehaug/MLwPython/blob/master/Course_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i0B4fNelHOlO"
      },
      "source": [
        "# About this Introduction to the Winter School"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n_5oRe0SXilM"
      },
      "source": [
        "Basic introduction on how to perform typical machine learning tasks with Python.\n",
        "\n",
        "PD Dr. Sigve Haug, 2021. https://github.com/sigvehaug/MLwPython\n",
        "\n",
        "Based on notebooks by Mykhailo Vladymyrov & Aris Marcolongo, 2020. https://github.com/neworldemancer/DSF5\n",
        "\n",
        "This work is licensed under <a href=\"https://creativecommons.org/share-your-work/public-domain/cc0/\">CC0</a>.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wkNfK9RyubTH"
      },
      "source": [
        "# Machine Learning (ML) in Context\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ve-fq1w40Oct"
      },
      "source": [
        "Societal development may be seen as a process boosted by technological revolutions:\n",
        "\n",
        "* 10k BC    Agricultural/Neolithic\n",
        "* 1760-1840 Industrial \n",
        "* 1850-1900 Electromagnetic\n",
        "* 1960-2000 Information\n",
        "* 2010-     Biocognitive (gene design and artificial and extended intelligence)\n",
        "\n",
        "AI has a huge automatization potential (already happening). Humans are outsourcing cognitive (brain) tasks. The comprehensive impact on society is hard to foresee. Some scholars even talk about the end of humanity (singularity). When one talks about AI, one normally means machine learning algorithms."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HkcwQ3BQ0RTE"
      },
      "source": [
        "In the CAS Applied Data Science we are here:\n",
        "* M1 Data Management and Acquisition\n",
        "* M2 Statistical Inference\n",
        "* M3 **Machine Learning with focus on Deep Learning**\n",
        "* M4 Best Practices and Ethics\n",
        "* M5 Electives\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qEVu2AHz0igO"
      },
      "source": [
        "\n",
        "In the scientific/data science process we are in the loops of this diagram here:\n",
        "<img src=\"https://github.com/sigvehaug/MLwPython/raw/master/figures/2013-sciencemethod.png\" width=\"60%\"/>\n",
        "\n",
        "In future the full process may be taken over by a (combination) of machine learning algorithms."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9SxiIczg1s1k"
      },
      "source": [
        "# What is ML?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xsd1MyT9eIdW"
      },
      "source": [
        "Unlike classical algorithms, created by human to analyze some data:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XtoqE5XO3L1j"
      },
      "source": [
        "<img src=\"https://github.com/neworldemancer/DSF5/raw/master/figures/alg_1.png\" width=\"60%\"/>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cu4Uq4k_ePoo"
      },
      "source": [
        "in machine learning the data itself is used for to define the algorithm:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e2xIgm223vfa"
      },
      "source": [
        "<img src=\"https://github.com/neworldemancer/DSF5/raw/master/figures/alg_2.png\" width=\"60%\"/>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LvAyI1uzfBUT"
      },
      "source": [
        "A ML definition (Tom Mitchell 1998):\n",
        "\n",
        "\"A computer program is said to learn from experience E with respect to some class of tasks T and performance measure P, if its performance at tasks in T, as measured by P, improves with experience E.\"\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "18P1PvfR-6CL"
      },
      "source": [
        "# ML Tasks\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "waORW396_FjT"
      },
      "source": [
        "The typical ML task categorisation with some applicartion examples.\n",
        "\n",
        "<img src=\"https://github.com/sigvehaug/MLwPython/raw/master/figures/ML-Categories.jpg\" width=\"60%\"/>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "70_dMCX340Rm"
      },
      "source": [
        "## Classification versus regression\n",
        "\n",
        "The two main tasks handled by (supervised) ML is regression and classification.\n",
        "In regression we aim at modeling the relationship between the system's response (dependent variable) and one or more explanatory variables (independent variables).\n",
        "\n",
        "Examples of regression would be predicting the temperature for each day of the year, or expenses of the household as a function of the number of children and adults.\n",
        "\n",
        "In classification the aim is to identify what class does a data-point belong to. For example, the species or the iris plant based on the size of its petals, or whether an email is spam or not based on its content.\n",
        "\n",
        "In this introduction we don't cover clustering and reinforcement learning.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l8n3ZHQkAlZB"
      },
      "source": [
        "\n",
        "## ML Algorithms\n",
        "\n",
        "ML researchers have designed, tested and implemented tens, hundreds, thousands of ML algorithms. Which one to choose depends on the task, the data and the cost (time, ethics, etc). When doing ML, one needs to briefly know the main categories, which tools/implementations to use and try a few algorithms, fine tune the best and bring it into production for ones task.\n",
        "\n",
        "A good way to get an overview is just to look at the list of implementations in scikit-learn: https://scikit-learn.org/stable/user_guide.html\n",
        "\n",
        "This only one way to make an ML cheet sheet:\n",
        "\n",
        "<img src=\"https://github.com/sigvehaug/MLwPython/raw/master/figures/cheatsheet.png\" width=\"60%\"/>\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qBXGs0xRERuv"
      },
      "source": [
        "# ML Performance\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5bH2anQxFQVr"
      },
      "source": [
        "## Overfitting and underfitting\n",
        "\n",
        "When doing ML, the goal is to achieve a minimal bias and a minimal variance. In this case the generalisation will be optimal. Minimal bias and variance are related to under- and overfitting. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lNsD3FQS4JP7"
      },
      "source": [
        "<img src=\"https://github.com/neworldemancer/DSF5/raw/master/figures/Bias_variance_1.png\" width=\"35%\"/>\n",
        "\n",
        "<img src=\"https://github.com/neworldemancer/DSF5/raw/master/figures/Bias_variance_2.png\" width=\"60%\"/>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QoONru7ji3QD"
      },
      "source": [
        "## Training and test data\n",
        "\n",
        "To measure model performance in an unbiassed way, we need to use different data than the data that the model was trained on. For this we use the 'train-test' split: e.g. 20% of all available dataset is reserved for model performance test, and the remaining 80% is used for actual model training."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wNmV5Z9QGQ_Q"
      },
      "source": [
        "## Performance Measures"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lx37P09Vkepw"
      },
      "source": [
        "### Regression:\n",
        "* Mean Square Error: $\\textrm{MSE}=\\frac{1}{n}\\sum_i(y_i - \\hat y(\\bar x_i))^2$\n",
        "* Mean Absolute Error: $\\textrm{MAE}=\\frac{1}{n}\\sum_i|y_i - \\hat y(\\bar x_i)|$\n",
        "* Median Absolute Deviation: $\\textrm{MAD}=\\textrm{median}(|y_i - \\hat y(\\bar x_i)|)$\n",
        "* Fraction of the explained variance: $R^2=1-\\frac{\\sum_i(y_i - \\hat y(\\bar x_i))^2}{\\sum_i(y_i - \\bar y)^2}$, where $\\bar y=\\frac{1}{n}\\sum_i y_i$\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZSH3blOw36jz"
      },
      "source": [
        "\n",
        "### Classification:\n",
        "* Confusion matrix \n",
        "\n",
        "<img src=\"https://github.com/neworldemancer/DSF5/raw/master/figures/confusion_mtr.png\" width=\"60%\"/>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MK2gGVJyfdUJ"
      },
      "source": [
        "* Accuracy $=\\frac{\\textrm{TP} + \\textrm{TN}}{\\textrm{TP} + \\textrm{FP} + \\textrm{FN} + \\textrm{TN}}$\n",
        "* Precision $=\\frac{\\textrm{TP}}{\\textrm{TP} + \\textrm{FP}}$ \n",
        "* Recall $=\\frac{\\textrm{TP}}{\\textrm{TP} + \\textrm{FN}}$\n",
        "* F1 $=2\\frac{\\textrm{Precision} \\cdot \\textrm{Recall}}{\\textrm{Precision} + \\textrm{Recall}} = \\frac{2 \\textrm{TP}}{2 \\textrm{TP} + \\textrm{FP} + \\textrm{FN}}$\n",
        "* Threat score (TS), or Intersection over Union: $\\mathrm{IoU}=\\frac{\\mathrm{TP}}{\\mathrm{TP}+\\mathrm{FN}+\\mathrm{FP}}$\n",
        "\n",
        "\n",
        "During model optimization the used measure in most cases must be differentiable. To this end usually some measure of similarities of distributions are employed (e.g. cross-entropy)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XMN7ZVD0GbdO"
      },
      "source": [
        "# ML Data / Experience"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VVUV9pxXtVhZ"
      },
      "source": [
        "\n",
        "Data is any sequence of symbols. For the current ML tools (Python scikit-lear, tensorflow, etc) data must be in numbers in a table (dataframe), one, two, or higher dimensional (tensor). So any data, like images, videos, sound, text ... must be turned into a table before processeing it with ML. Cleaning and preprocessing data into these tables are the normally the most time consuming part in data science and ML projects.\n",
        "\n",
        "And, if your data is rubbish, the results will be rubbish, too."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RHRXds9U9134"
      },
      "source": [
        "# The `scikit-learn` Interface - some words"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_SObKh_3ufiO"
      },
      "source": [
        "In this course we will primarily use the scikit-learn module. You can find extensive documentation with examples in the user guide\n",
        "\n",
        "The module contains A LOT of different machine learning methods, and here we will cover only few of them. What is great about scikit-learn is that it has a uniform and consistent interface.\n",
        "\n",
        "All the different ML approaches are implemented as classes with a set of same main methods:\n",
        "\n",
        "fitter = ...: Create object.\n",
        "fitter.fit(x, y[, sample_weight]): Fit model.\n",
        "y_pred = fitter.predict(X): Predict using the linear model.\n",
        "s = score(x, y[, sample_weight]): Return an appropriate measure of model performance.\n",
        "This allows one to easily replace one approach with another and find the best one for the problem at hand, by simply using another regression/classification object, while the rest of the code can remain the same.\n",
        "\n",
        "It is useful to know that generally in scikit-learn the input data is represented as a design matrix $X$ of dimensions n_samples x n_features , whereas the supervised labels/values are stored in a matrix $Y$ of dimensions n_samples x n_target ."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZyEP5G5xGycf"
      },
      "source": [
        "# A first example - linear regression for house prices "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hh6lII-Hz8u-"
      },
      "source": [
        "In many cases the scalar value of interest - dependent variable - is (or can be approximated as) linear combination of the independent variables. \n",
        "\n",
        "In linear regression the estimator is searched in the form: $$\\hat{y}(w, x) = w_0 + w_1 x_1 + ... + w_p x_p$$\n",
        "\n",
        "The parameters $w = (w_1,..., w_p)$ and $w_0$ are designated as `coef_` and `intercept_` in `sklearn`.\n",
        "\n",
        "Reference: https://scikit-learn.org/stable/modules/linear_model.html"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NVSRftm8X1m1"
      },
      "source": [
        "## Load libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hVJn0ilgOS8F",
        "scrolled": true
      },
      "source": [
        "# Scikit-learn (formerly scikits.learn and also known as sklearn) is a free \n",
        "# software machine learning library for the Python programming language. \n",
        "# It features various classification, regression and clustering algorithms, \n",
        "# and is designed to interoperate with the Python numerical and scientific \n",
        "# libraries NumPy and SciPy. (from wiki)\n",
        "\n",
        "from sklearn import linear_model\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# common visualization module\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "# numeric module\n",
        "import numpy as np\n",
        "# data analysis module\n",
        "import pandas as pd\n",
        "\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s_wxOrdWko8W"
      },
      "source": [
        "## Load and preprocess dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A-45usskInlD"
      },
      "source": [
        "Subset of the Ames Houses dataset: http://jse.amstat.org/v19n3/decock.pdf"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dVv2ID96IyN0"
      },
      "source": [
        "def house_prices_dataset(return_df=False, price_max=400000, area_max=40000):\n",
        "#  path = 'data/AmesHousing.csv'\n",
        "  path = 'https://raw.githubusercontent.com/sigvehaug/MLwPython/master/data/AmesHousing.csv'\n",
        "  df = pd.read_csv(path, na_values=('NaN', ''), keep_default_na=False)\n",
        "  \n",
        "  # Clean up the column names\n",
        "  rename_dict = {k:k.replace(' ', '').replace('/', '') for k in df.keys()}\n",
        "  df.rename(columns=rename_dict, inplace=True)\n",
        "  \n",
        "  # Select the columns to be used and make feature and target dataframe\n",
        "  useful_fields = ['LotArea',\n",
        "                  'Utilities', 'OverallQual', 'OverallCond',\n",
        "                  'YearBuilt', 'YearRemodAdd', 'ExterQual', 'ExterCond',\n",
        "                  'HeatingQC', 'CentralAir', 'Electrical',\n",
        "                  '1stFlrSF', '2ndFlrSF','GrLivArea',\n",
        "                  'FullBath', 'HalfBath',\n",
        "                  'BedroomAbvGr', 'KitchenAbvGr', 'KitchenQual', 'TotRmsAbvGrd',\n",
        "                  'Functional','PoolArea',\n",
        "                  'YrSold', 'MoSold'\n",
        "                  ]\n",
        "  target_field = 'SalePrice'\n",
        "\n",
        "  df.dropna(axis=0, subset=useful_fields+[target_field], inplace=True)\n",
        "\n",
        "  cleanup_nums = {'Street':      {'Grvl': 0, 'Pave': 1},\n",
        "                  'LotFrontage': {'NA':0},\n",
        "                  'Alley':       {'NA':0, 'Grvl': 1, 'Pave': 2},\n",
        "                  'LotShape':    {'IR3':0, 'IR2': 1, 'IR1': 2, 'Reg':3},\n",
        "                  'Utilities':   {'ELO':0, 'NoSeWa': 1, 'NoSewr': 2, 'AllPub': 3},\n",
        "                  'LandSlope':   {'Sev':0, 'Mod': 1, 'Gtl': 3},\n",
        "                  'ExterQual':   {'Po':0, 'Fa': 1, 'TA': 2, 'Gd': 3, 'Ex':4},\n",
        "                  'ExterCond':   {'Po':0, 'Fa': 1, 'TA': 2, 'Gd': 3, 'Ex':4},\n",
        "                  'BsmtQual':    {'NA':0, 'Po':1, 'Fa': 2, 'TA': 3, 'Gd': 4, 'Ex':5},\n",
        "                  'BsmtCond':    {'NA':0, 'Po':1, 'Fa': 2, 'TA': 3, 'Gd': 4, 'Ex':5},\n",
        "                  'BsmtExposure':{'NA':0, 'No':1, 'Mn': 2, 'Av': 3, 'Gd': 4},\n",
        "                  'BsmtFinType1':{'NA':0, 'Unf':1, 'LwQ': 2, 'Rec': 3, 'BLQ': 4, 'ALQ':5, 'GLQ':6},\n",
        "                  'BsmtFinType2':{'NA':0, 'Unf':1, 'LwQ': 2, 'Rec': 3, 'BLQ': 4, 'ALQ':5, 'GLQ':6},\n",
        "                  'HeatingQC':   {'Po':0, 'Fa': 1, 'TA': 2, 'Gd': 3, 'Ex':4},\n",
        "                  'CentralAir':  {'N':0, 'Y': 1},\n",
        "                  'Electrical':  {'':0, 'NA':0, 'Mix':1, 'FuseP':2, 'FuseF': 3, 'FuseA': 4, 'SBrkr': 5},\n",
        "                  'KitchenQual': {'Po':0, 'Fa': 1, 'TA': 2, 'Gd': 3, 'Ex':4},\n",
        "                  'Functional':  {'Sal':0, 'Sev':1, 'Maj2': 2, 'Maj1': 3, 'Mod': 4, 'Min2':5, 'Min1':6, 'Typ':7},\n",
        "                  'FireplaceQu': {'NA':0, 'Po':1, 'Fa': 2, 'TA': 3, 'Gd': 4, 'Ex':5},\n",
        "                  'PoolQC':      {'NA':0, 'Fa': 1, 'TA': 2, 'Gd': 3, 'Ex':4},\n",
        "                  'Fence':       {'NA':0, 'MnWw': 1, 'GdWo': 2, 'MnPrv': 3, 'GdPrv':4},\n",
        "                  }\n",
        "\n",
        "  df_X = df[useful_fields].copy()                              \n",
        "  df_X.replace(cleanup_nums, inplace=True)  # convert continous categorial variables to numerical\n",
        "  df_Y = df[target_field].copy()\n",
        "\n",
        "  # Convert to numpy arrays and return only rows with values below given maxima \n",
        "  x = df_X.to_numpy().astype(np.float32)\n",
        "  y = df_Y.to_numpy().astype(np.float32)\n",
        "\n",
        "  if price_max>0:\n",
        "    idxs = y<price_max\n",
        "    x = x[idxs]\n",
        "    y = y[idxs]\n",
        "\n",
        "  if area_max>0:\n",
        "    idxs = x[:,0]<area_max\n",
        "    x = x[idxs]\n",
        "    y = y[idxs]\n",
        "\n",
        "  return (x, y, df) if return_df else (x,y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YqWU0eHts1RM"
      },
      "source": [
        "x, y, df = house_prices_dataset(return_df=True)\n",
        "print(x.shape, y.shape)\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "91nj7znzMEpA"
      },
      "source": [
        "plt.plot(x[:, 0], y, '.r')\n",
        "plt.xlabel('Area / ft^2')\n",
        "plt.ylabel('Price / USD');"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RH4Zo2BA190T"
      },
      "source": [
        "## Train/fit the ML model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p-Vpniu55wk5"
      },
      "source": [
        "# Make train/test split\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2)\n",
        "\n",
        "# Fit the model\n",
        "reg = linear_model.LinearRegression()\n",
        "reg.fit(x_train, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r5FBnR9y50g0"
      },
      "source": [
        "## Evaluate and plot the results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LvkIvxZk48y8"
      },
      "source": [
        "# Evaluate MSE, MAD, and R2 on train and test datasets\n",
        "\n",
        "# Prediction:\n",
        "y_p_train = reg.predict(x_train)\n",
        "y_p_test = reg.predict(x_test)\n",
        "\n",
        "# mse\n",
        "print('Train MSE = %5.2f' % np.std(y_train - y_p_train))\n",
        "print('Test MSE = %5.2f' % np.std(y_test - y_p_test))\n",
        "# mse\n",
        "print('Train MAE = %5.2f' % np.mean(np.abs(y_train - y_p_train)))\n",
        "print('Test MAE = %5.2f' % np.mean(np.abs(y_test - y_p_test)))\n",
        "# R2\n",
        "print('Train R2 = %5.2f' % reg.score(x_train, y_train))\n",
        "print('Test R2 = %5.2f' % reg.score(x_test, y_test))\n",
        "\n",
        "# Plot y vs predicted y for test and train parts\n",
        "plt.figure(figsize=(10,10))\n",
        "plt.plot(y_train, y_p_train, 'b.', label='Train')\n",
        "plt.plot(y_test, y_p_test, 'r.', label='Test')\n",
        "\n",
        "plt.plot([0], [0], 'w.')  # dummy to have origin\n",
        "plt.xlabel('True Price')\n",
        "plt.ylabel('Predicted Price')\n",
        "#plt.gca().set_aspect('equal')\n",
        "plt.legend()\n",
        "plt.plot()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zI6s2Amob48j"
      },
      "source": [
        "# Hands-on / Hackathon Session"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J-GcAYuT0MGI"
      },
      "source": [
        "Use the linear regression example as a template and fit house prices with a decision tree model. You can write, copy ande paste your solutions here below. Have fun! Do you see overfitting in your solution?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a1cOkx1F6tmH"
      },
      "source": [
        "# Import libraries\n",
        "#from sklearn import tree\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ylfFUWzq7cR2"
      },
      "source": [
        "# The rest of the Winter School"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xkSL59Sg7hmG"
      },
      "source": [
        "Now we have seen how to use the Python library scikit-learn for ML. Tomorrow and the rest of the week, you will learn about deep neural networks and use TensorFlow to perform ML."
      ]
    }
  ]
}